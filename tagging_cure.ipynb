{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a847e5c0-e611-48d1-9655-653d41b08475",
   "metadata": {},
   "source": [
    "**Firstly grabbing our filtered dataset according to mappings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6627fac4-9e51-4e78-916f-3df0e6a8679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ArrDelay_mean=7.159954113241544, DepDelay_mean=8.155785553305384, ActualElapsedTime_mean=122.11903171401364, Distance_mean=715.1781956065518, origin_lat_mean=37.099659857406145, origin_long_mean=-92.27161607308254, dest_lat_mean=37.09915724198568, dest_long_mean=-92.26712071709692, Season_mean=1.4983448205364176, origin_prcp_mean=25.696228836739326, origin_tmax_mean=205.3709193033514, origin_tmin_mean=94.5765910747429, origin_awnd_mean=38.636158741871185, dest_prcp_mean=25.612486723460716, dest_tmax_mean=205.36587148443542, dest_tmin_mean=94.56188964755093, dest_awnd_mean=38.63819560488218, record_id_mean=327715972788.13043, ArrDelay_stddev=30.939682127010055, DepDelay_stddev=28.437824166810305, ActualElapsedTime_stddev=70.31234179026457, Distance_stddev=569.0274209367315, origin_lat_stddev=5.5991075699082264, origin_long_stddev=16.70378425786922, dest_lat_stddev=5.5997072673137644, dest_long_stddev=16.697214735116198, Season_stddev=1.113054367950728, origin_prcp_stddev=83.85304742810695, origin_tmax_stddev=105.31647510766037, origin_tmin_stddev=98.13591478796421, origin_awnd_stddev=20.659449046652067, dest_prcp_stddev=83.51747812154092, dest_tmax_stddev=105.35316315020064, dest_tmin_stddev=98.17185756564169, dest_awnd_stddev=20.577454061628384, record_id_stddev=192507839455.49905)\n",
      "[Row(ArrDelay=0.8028539461002842, DepDelay=1.014290484303599, ActualElapsedTime=-1.0541397118460951, Distance=-0.936999125154347, origin_lat=0.5176406036866625, origin_long=0.5615334314835698, dest_lat=0.46755514226554973, dest_long=0.3577085545013415, Season=0, origin_prcp=-0.24681546433340593, origin_tmax=-1.2094111502796285, origin_tmin=-0.9025909756496843, origin_awnd=-0.36962063821874525, dest_prcp=-0.3066721756874351, dest_tmax=-0.9431693222420933, dest_tmin=-0.8511796732752872, dest_awnd=0.5035513316703207, record_id=352187318272)]\n"
     ]
    }
   ],
   "source": [
    "# need to grab mean and std for each column so that we can normalize the df and apply clustering\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "joined = spark.read.parquet('./FINAL_processed_data')\n",
    "\n",
    "columns = joined.columns\n",
    "#print(joined.printSchema())\n",
    "\n",
    "# below is for mean, standard deviation based scaling\n",
    "\n",
    "stats = joined.select(*[[F.mean(c).alias(c+'_mean') for c in joined.columns] + [F.stddev_pop(c).alias(c+'_stddev') for c in joined.columns]]).collect()[0]\n",
    "# scaling join column\n",
    "for column in columns:\n",
    "    if column != 'Season' and column!= 'record_id':\n",
    "        joined = joined.withColumn(column,(joined[column]-stats[column+'_mean'])/(stats[column+'_stddev']))\n",
    "\n",
    "# below is for max, min based scaling\n",
    "'''stats = joined.select(*[[F.max(c).alias(c+'_max') for c in joined.columns] + [F.min(c).alias(c+'_min') for c in joined.columns]]).collect()[0]\n",
    "# scaling join column\n",
    "for column in columns:\n",
    "    if column != 'Season':\n",
    "        joined = joined.withColumn(column,(joined[column]-stats[column+'_min'])/(stats[column+'_max'] - stats[column+'_min']))'''\n",
    "\n",
    "print(stats)\n",
    "\n",
    "\n",
    "print(joined.take(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1882822-1c17-4549-a2c9-ecf5e94d21c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ArrDelay: double (nullable = true)\n",
      " |-- DepDelay: double (nullable = true)\n",
      " |-- ActualElapsedTime: double (nullable = true)\n",
      " |-- Distance: double (nullable = true)\n",
      " |-- origin_lat: double (nullable = true)\n",
      " |-- origin_long: double (nullable = true)\n",
      " |-- dest_lat: double (nullable = true)\n",
      " |-- dest_long: double (nullable = true)\n",
      " |-- Season: long (nullable = true)\n",
      " |-- origin_prcp: double (nullable = true)\n",
      " |-- origin_tmax: double (nullable = true)\n",
      " |-- origin_tmin: double (nullable = true)\n",
      " |-- origin_awnd: double (nullable = true)\n",
      " |-- dest_prcp: double (nullable = true)\n",
      " |-- dest_tmax: double (nullable = true)\n",
      " |-- dest_tmin: double (nullable = true)\n",
      " |-- dest_awnd: double (nullable = true)\n",
      " |-- record_id: long (nullable = true)\n",
      "\n",
      "None\n",
      "tagged configuration for cure: k=3 num_reps=4 season=0\n",
      "tagged configuration for cure: k=4 num_reps=4 season=0\n",
      "tagged configuration for cure: k=5 num_reps=4 season=0\n",
      "tagged configuration for cure: k=6 num_reps=4 season=0\n",
      "tagged configuration for cure: k=7 num_reps=4 season=0\n",
      "tagged configuration for cure: k=8 num_reps=4 season=0\n",
      "tagged configuration for cure: k=9 num_reps=4 season=0\n",
      "tagged configuration for cure: k=3 num_reps=4 season=1\n",
      "tagged configuration for cure: k=4 num_reps=4 season=1\n",
      "tagged configuration for cure: k=5 num_reps=4 season=1\n",
      "tagged configuration for cure: k=6 num_reps=4 season=1\n",
      "tagged configuration for cure: k=7 num_reps=4 season=1\n",
      "tagged configuration for cure: k=8 num_reps=4 season=1\n",
      "tagged configuration for cure: k=9 num_reps=4 season=1\n",
      "tagged configuration for cure: k=3 num_reps=4 season=2\n",
      "tagged configuration for cure: k=4 num_reps=4 season=2\n",
      "tagged configuration for cure: k=5 num_reps=4 season=2\n",
      "tagged configuration for cure: k=6 num_reps=4 season=2\n",
      "tagged configuration for cure: k=7 num_reps=4 season=2\n",
      "tagged configuration for cure: k=8 num_reps=4 season=2\n",
      "tagged configuration for cure: k=9 num_reps=4 season=2\n",
      "tagged configuration for cure: k=3 num_reps=4 season=3\n",
      "tagged configuration for cure: k=4 num_reps=4 season=3\n",
      "tagged configuration for cure: k=5 num_reps=4 season=3\n",
      "tagged configuration for cure: k=6 num_reps=4 season=3\n",
      "tagged configuration for cure: k=7 num_reps=4 season=3\n",
      "tagged configuration for cure: k=8 num_reps=4 season=3\n",
      "tagged configuration for cure: k=9 num_reps=4 season=3\n",
      "tagged configuration for cure: k=3 num_reps=4 season=4\n",
      "tagged configuration for cure: k=4 num_reps=4 season=4\n",
      "tagged configuration for cure: k=5 num_reps=4 season=4\n",
      "tagged configuration for cure: k=6 num_reps=4 season=4\n",
      "tagged configuration for cure: k=7 num_reps=4 season=4\n",
      "tagged configuration for cure: k=8 num_reps=4 season=4\n",
      "tagged configuration for cure: k=9 num_reps=4 season=4\n",
      "tagged configuration for cure: k=3 num_reps=5 season=0\n",
      "tagged configuration for cure: k=4 num_reps=5 season=0\n",
      "tagged configuration for cure: k=5 num_reps=5 season=0\n",
      "tagged configuration for cure: k=6 num_reps=5 season=0\n",
      "tagged configuration for cure: k=7 num_reps=5 season=0\n",
      "tagged configuration for cure: k=8 num_reps=5 season=0\n",
      "tagged configuration for cure: k=9 num_reps=5 season=0\n",
      "tagged configuration for cure: k=3 num_reps=5 season=1\n",
      "tagged configuration for cure: k=4 num_reps=5 season=1\n",
      "tagged configuration for cure: k=5 num_reps=5 season=1\n",
      "tagged configuration for cure: k=6 num_reps=5 season=1\n",
      "tagged configuration for cure: k=7 num_reps=5 season=1\n",
      "tagged configuration for cure: k=8 num_reps=5 season=1\n",
      "tagged configuration for cure: k=9 num_reps=5 season=1\n",
      "tagged configuration for cure: k=3 num_reps=5 season=2\n",
      "tagged configuration for cure: k=4 num_reps=5 season=2\n",
      "tagged configuration for cure: k=5 num_reps=5 season=2\n",
      "tagged configuration for cure: k=6 num_reps=5 season=2\n",
      "tagged configuration for cure: k=7 num_reps=5 season=2\n",
      "tagged configuration for cure: k=8 num_reps=5 season=2\n",
      "tagged configuration for cure: k=9 num_reps=5 season=2\n",
      "tagged configuration for cure: k=3 num_reps=5 season=3\n",
      "tagged configuration for cure: k=4 num_reps=5 season=3\n",
      "tagged configuration for cure: k=5 num_reps=5 season=3\n",
      "tagged configuration for cure: k=6 num_reps=5 season=3\n",
      "tagged configuration for cure: k=7 num_reps=5 season=3\n",
      "tagged configuration for cure: k=8 num_reps=5 season=3\n",
      "tagged configuration for cure: k=9 num_reps=5 season=3\n",
      "tagged configuration for cure: k=3 num_reps=5 season=4\n",
      "tagged configuration for cure: k=4 num_reps=5 season=4\n",
      "tagged configuration for cure: k=5 num_reps=5 season=4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from math import sqrt\n",
    "from pyspark.sql import Row\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# for cure we only choose the distance to the closest representative to x\n",
    "def cure_tag(clusters,x):\n",
    "    vals = []\n",
    "    for val in x:\n",
    "        vals.append(val)\n",
    "    vals = np.array(vals)\n",
    "    distance = None\n",
    "    closest_cluster = None\n",
    "    for i,cluster in enumerate(clusters):       \n",
    "        for representative in cluster:\n",
    "            dist = np.linalg.norm(representative-vals)\n",
    "            if distance is None or dist < distance:\n",
    "                distance=dist\n",
    "                closest_cluster = i\n",
    "    return closest_cluster\n",
    "\n",
    "def wrapped_cure_tag(clusters):\n",
    "    return F.udf(lambda c: cure_tag(clusters,c),T.IntegerType())\n",
    "    \n",
    "# num features\n",
    "num_features = len(joined.columns)\n",
    "\n",
    "print(joined.printSchema())\n",
    "\n",
    "# num_clusters\n",
    "for num_reps in range(4,8):\n",
    "    for season in range(5):\n",
    "        for k in range(3,10):\n",
    "            fraction = 0.2\n",
    "            # getting clusters as a list of lists of representatives\n",
    "            if season != 4:\n",
    "                clusters = spark.read\\\n",
    "                                .parquet('./CURE_Clusters/k='+str(k)+'_season='+str(season)+'_num_reps='+str(num_reps)+'_fraction='+str(fraction))\\\n",
    "                                .toPandas().to_numpy()\n",
    "            else:\n",
    "                clusters = spark.read\\\n",
    "                                .parquet('./CURE_Clusters/k='+str(k)+'_season=EVERYTHING'+'_num_reps='+str(num_reps)+'_fraction='+str(fraction))\\\n",
    "                                .toPandas().to_numpy()\n",
    "            #print(clusters)\n",
    "            if season!=4:\n",
    "                final_dat = joined.where(joined.Season == season).drop('Season')\n",
    "            else:\n",
    "                final_dat = joined.drop('Season')\n",
    "            \n",
    "            # we select record_id to tag and we are good\n",
    "            #print(final_dat.columns)\n",
    "            final_dat = final_dat.withColumn('tag',wrapped_cure_tag(clusters)(F.array(*final_dat.columns[:-1]))).select('record_id','tag')\n",
    "            print('tagged configuration for cure: k='+str(k)+' num_reps='+str(num_reps) + ' season='+str(season))\n",
    "            \n",
    "            # writing mappings to disk\n",
    "            \n",
    "            \n",
    "            if season !=4:\n",
    "                final_dat.coalesce(20).write.parquet('./CURE_Mapping/k='+str(k)+'_season='+str(season)+'_num_reps='+str(num_reps))\n",
    "            else:\n",
    "                final_dat.coalesce(20).write.parquet('./CURE_Mapping/k='+str(k)+'_season=EVERYTHING'+'_num_reps='+str(num_reps))\n",
    "            \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b9b24-dc91-4428-a60f-14284d739035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 3 in Python 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
